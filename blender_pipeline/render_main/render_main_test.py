# è„šæœ¬1: ä¸»å›¾æ¸²æŸ“è„šæœ¬ (render_main.py) - æ–­ç‚¹ç»­ä¼ ä¼˜åŒ–ç‰ˆ
# åŠŸèƒ½ï¼šæ ¹æ®ã€å·²ç­›é€‰å¥½ã€‘çš„Maskæ–‡ä»¶åˆ—è¡¨ï¼Œæ™ºèƒ½è·³è¿‡å·²æ¸²æŸ“çš„ä¸»å›¾ï¼Œä»…æ¸²æŸ“ç¼ºå¤±çš„éƒ¨åˆ†ï¼Œå¹¶è¿½åŠ ç”ŸæˆCSVæ—¥å¿—ã€‚
# å‰ç½®è¦æ±‚ï¼šå¿…é¡»å…ˆè¿è¡Œrender_mask.pyï¼Œç¡®ä¿masksç›®å½•å­˜åœ¨ã€‚

import time
import bpy
import os
import math
import re
from mathutils import Vector
from PIL import Image
import tempfile
import numpy as np
import csv
import argparse
import sys


def get_command_line_args():
    """
    è§£æä»å‘½ä»¤è¡Œä¼ é€’ç»™Blenderè„šæœ¬çš„å‚æ•°ã€‚
    """
    argv = sys.argv
    if "--" not in argv:
        return None
    
    args_to_parse = argv[argv.index("--") + 1:]
    parser = argparse.ArgumentParser(description="é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶çš„Blenderä¸»å›¾æ¸²æŸ“è„šæœ¬ã€‚")
    
    parser.add_argument("--gpu-index", dest="target_gpu_index", type=int, required=True, help="è¦ä½¿ç”¨çš„GPUè®¾å¤‡ç´¢å¼• (å¿…éœ€)")
    parser.add_argument("--object", dest="object_blend_path", type=str, required=True, help="è¦æ¸²æŸ“çš„ç‰©ä½“.blendæ–‡ä»¶è·¯å¾„ (å¿…éœ€)")
    parser.add_argument("--scene", dest="scene_blend_path", type=str, required=True, help="æ¸²æŸ“æ‰€ç”¨çš„åœºæ™¯.blendæ–‡ä»¶è·¯å¾„ (å¿…éœ€)")
    parser.add_argument("--output", dest="output_path", type=str, required=True, help="æ¸²æŸ“è¾“å‡ºçš„ã€å®Œæ•´ã€‘ç›®æ ‡ç›®å½• (å¿…éœ€)")

    try:
        args = parser.parse_args(args=args_to_parse)
        return args
    except SystemExit:
        return None

# --- æ‰§è¡Œå‚æ•°è§£æå¹¶é…ç½®è„šæœ¬å˜é‡ ---
cli_args = get_command_line_args()
if cli_args is None:
    print("âŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„å‘½ä»¤è¡Œå‚æ•°æˆ–è§£æå¤±è´¥ã€‚")
    print("   ç¤ºä¾‹: blender -b -P render_main.py -- --scene <path> --object <path> --output <path> --gpu-index 0")
    bpy.ops.wm.quit_blender()

target_gpu_index = cli_args.target_gpu_index
object_blend_path = cli_args.object_blend_path
scene_blend_path = cli_args.scene_blend_path
output_path = cli_args.output_path

os.makedirs(output_path, exist_ok=True)
num_frames = 10
move_step = [0.06, 0.06, 0] # æ³¨æ„ï¼šæ­¤å€¼åº”ä¸Maskè„šæœ¬ä¿æŒä¸€è‡´ä»¥ç¡®ä¿ä½ç½®æ­£ç¡®

### === å·¥å…·å‡½æ•° (ä¿æŒä¸å˜) === ###
def direction_to_euler(direction_vec):
    target = Vector(direction_vec)
    rot_quat = target.to_track_quat('-Z', 'Y')
    return rot_quat.to_euler()

def get_scene_bounds():
    min_x = min_y = min_z = float('inf')
    max_x = max_y = max_z = float('-inf')
    for obj in bpy.data.objects:
        if obj.type == 'MESH' and not obj.hide_get():
            bbox_world = [obj.matrix_world @ Vector(corner) for corner in obj.bound_box]
            for v in bbox_world:
                min_x, min_y, min_z = min(min_x, v.x), min(min_y, v.y), min(min_z, v.z)
                max_x, max_y, max_z = max(max_x, v.x), max(max_y, v.y), max(max_z, v.z)
    return Vector((min_x, min_y, min_z)), Vector((max_x, max_y, max_z))

def auto_adjust_object_size(obj, scene_bounds_min, scene_bounds_max):
    size = scene_bounds_max - scene_bounds_min
    avg_dim = (size.x + size.y + size.z) / 3
    target_size = avg_dim * 0.005
    current_size = max(obj.dimensions.x, obj.dimensions.y, obj.dimensions.z)
    if current_size == 0: return
    scale_factor = target_size / current_size
    obj.scale *= scale_factor
    bpy.context.view_layer.objects.active = obj
    obj.select_set(True)
    bpy.ops.object.transform_apply(location=False, rotation=False, scale=True)
    obj.select_set(False)

def adjust_lighting_to_target_brightness(target_brightness=0.4, preview_resolution=(128, 72), camera_list=None):
    scene = bpy.context.scene
    if camera_list: scene.camera = camera_list[0]
    old_x, old_y = scene.render.resolution_x, scene.render.resolution_y
    old_samples = scene.cycles.samples
    scene.render.resolution_x, scene.render.resolution_y = preview_resolution
    scene.cycles.samples = 32
    scene.render.image_settings.file_format = 'PNG'
    temp_file = os.path.join(tempfile.gettempdir(), "preview.png")
    scene.render.filepath = temp_file
    bpy.ops.render.render(write_still=True)
    time.sleep(1.5)
    img = Image.open(temp_file).convert('RGB')
    avg_brightness = np.asarray(img).astype(np.float32).mean() / 255.0
    if avg_brightness > 0:
        scale = target_brightness / avg_brightness
        for light in bpy.data.lights: light.energy *= scale
        if scene.world and scene.world.node_tree:
            for node in scene.world.node_tree.nodes:
                if node.type == 'BACKGROUND': node.inputs[1].default_value *= scale
    scene.render.resolution_x, scene.render.resolution_y = old_x, old_y
    scene.cycles.samples = old_samples

def find_ground_object_auto():
    candidates = [obj for obj in bpy.data.objects if obj.type == 'MESH' and not obj.hide_get()]
    for obj in candidates:
        if obj.name.lower() == "ground": return obj
    lowest, ground_obj = float('inf'), None
    for obj in candidates:
        z = min(v.z for v in [obj.matrix_world @ Vector(c) for c in obj.bound_box])
        if z < lowest: lowest, ground_obj = z, obj
    return ground_obj

def fix_ground_orientation(ground_obj):
    if ground_obj.scale.z < 0: ground_obj.scale.z = abs(ground_obj.scale.z)
    if abs(math.degrees(ground_obj.rotation_euler.x)) in [90, 180, 270]: ground_obj.rotation_euler.x = 0.0

def adjust_object_to_ground_with_ray(obj, ground_obj):
    scene, depsgraph = bpy.context.scene, bpy.context.evaluated_depsgraph_get()
    bbox_world = [obj.matrix_world @ Vector(corner) for corner in obj.bound_box]
    min_z = min(v.z for v in bbox_world)
    center_x = sum(v.x for v in bbox_world) / 8.0
    center_y = sum(v.y for v in bbox_world) / 8.0
    ray_origin = Vector((center_x, center_y, min_z + 0.01))
    hit, location, _, _, hit_obj, _ = scene.ray_cast(depsgraph, ray_origin, Vector((0, 0, -1)), distance=2.0)
    if hit and hit_obj == ground_obj: obj.location.z += location.z - min_z

def create_cameras_rings(camera_list, bounds_min, bounds_max, target_obj, rings_config):
    bbox_world = [target_obj.matrix_world @ Vector(corner) for corner in target_obj.bound_box]
    center = sum(bbox_world, Vector((0, 0, 0))) / 8.0
    scene_size = bounds_max - bounds_min
    max_span, scene_height = max(scene_size.x, scene_size.y), scene_size.z
    for ring_idx, (radius_ratio, height_ratio, cameras_count) in enumerate(rings_config):
        radius, height = max_span * radius_ratio, scene_height * height_ratio
        for i in range(cameras_count):
            angle = 2 * math.pi * i / cameras_count
            cam_loc = Vector((center.x + radius * math.cos(angle), center.y + radius * math.sin(angle), center.z + height))
            cam_dir = center - cam_loc
            cam_data = bpy.data.cameras.new(name=f"Camera_{ring_idx}_{i}")
            cam_obj = bpy.data.objects.new(name=f"Camera_{ring_idx}_{i}", object_data=cam_data)
            cam_obj.location = cam_loc
            cam_obj.rotation_euler = direction_to_euler(cam_dir)
            bpy.context.collection.objects.link(cam_obj)
            camera_list.append(cam_obj)

### === æ¸²æŸ“è®¾ç½® (ä¿æŒä¸å˜) === ###
scene = bpy.context.scene
scene.render.engine = 'CYCLES'
prefs = bpy.context.preferences.addons['cycles'].preferences
prefs.compute_device_type = 'CUDA'
prefs.get_devices()
cuda_devices = [d for d in prefs.devices if d.type == 'CUDA']
if target_gpu_index >= len(cuda_devices): raise IndexError("æŒ‡å®š GPU index è¶…å‡ºèŒƒå›´")
for i, d in enumerate(cuda_devices): d.use = (i == target_gpu_index)
scene.cycles.device = 'GPU'
scene.cycles.samples = 1024
scene.cycles.use_denoising = False
scene.cycles.denoiser = 'OPENIMAGEDENOISE'
scene.cycles.max_bounces = 32
scene.cycles.transparent_max_bounces = 32
scene.cycles.transmission_max_bounces = 12
scene.view_settings.view_transform = 'Filmic'
scene.view_settings.look = 'None'
scene.view_settings.gamma = 0.5

### === åŠ è½½ä¸å‡†å¤‡ (ä¿æŒä¸å˜) === ###
bpy.ops.wm.open_mainfile(filepath=scene_blend_path)
scene = bpy.context.scene
scene.render.resolution_x = 1024
scene.render.resolution_y = 1024
scene.render.resolution_percentage = 100

for light in bpy.data.lights: light.energy *= 0.3
if scene.world and scene.world.node_tree:
    for node in scene.world.node_tree.nodes:
        if node.type == 'BACKGROUND': node.inputs[1].default_value *= 0.3

with bpy.data.libraries.load(object_blend_path) as (data_from, data_to):
    data_to.objects = data_from.objects

imported_mesh_objs, empty_name = [], None
for o in data_to.objects:
    if o:
        bpy.context.collection.objects.link(o)
        if o.type == 'MESH': imported_mesh_objs.append(o)
        elif o.type == 'EMPTY' and empty_name is None: empty_name = o.name

if not imported_mesh_objs: raise RuntimeError("æœªæ‰¾åˆ°ä»»ä½• mesh ç±»å‹ä¸»ç‰©ä½“")
for obj in imported_mesh_objs: obj.select_set(True)
bpy.context.view_layer.objects.active = imported_mesh_objs[0]
bpy.ops.object.join()
main_obj = bpy.context.view_layer.objects.active
if empty_name: main_obj.name = empty_name

ground_obj = find_ground_object_auto()
if ground_obj: fix_ground_orientation(ground_obj)
bounds_min, bounds_max = get_scene_bounds()
auto_adjust_object_size(main_obj, bounds_min, bounds_max)
if ground_obj: adjust_object_to_ground_with_ray(main_obj, ground_obj)
start_location = list(main_obj.location)

camera_rings_config = [(0.01, 0.005, 10), (0.015, 0.008, 10), (0.02, 0.012, 10)]
camera_list = []
create_cameras_rings(camera_list, bounds_min, bounds_max, main_obj, camera_rings_config)

adjust_lighting_to_target_brightness(0.4, camera_list=camera_list)

# ==============================================================================
# ### === æ¸²æŸ“ä»»åŠ¡ç”Ÿæˆï¼šã€æ–­ç‚¹ç»­ä¼ ä¼˜åŒ–ç‰ˆã€‘ === ###
# ==============================================================================
output_image_dir = os.path.join(output_path, 'images')
output_mask_dir = os.path.join(output_path, 'test_masks_cryptomatte2')
os.makedirs(output_image_dir, exist_ok=True)

print("\n" + "="*50)
print("âš™ï¸ å¼€å§‹æ ¹æ®Maskå’Œå·²æœ‰çš„ä¸»å›¾ç”Ÿæˆå¢é‡æ¸²æŸ“ä»»åŠ¡...")

# 1. æ£€æŸ¥Maskç›®å½•æ˜¯å¦å­˜åœ¨
if not os.path.isdir(output_mask_dir):
    print(f"âŒ è‡´å‘½é”™è¯¯: Maskç›®å½• '{output_mask_dir}' ä¸å­˜åœ¨ã€‚")
    print("   è¯·ç¡®ä¿å·²è¿è¡Œ `render_mask.py`ã€‚")
    bpy.ops.wm.quit_blender()

# 2. è·å–æ‰€æœ‰ç†è®ºä¸Šéœ€è¦æ¸²æŸ“çš„Maskæ–‡ä»¶å (æ€»ä»»åŠ¡è“å›¾)
all_mask_filenames = sorted([f for f in os.listdir(output_mask_dir) if f.lower().endswith('.png')])

if not all_mask_filenames:
    print("âš ï¸ è­¦å‘Š: Maskç›®å½•ä¸ºç©ºï¼Œæ²¡æœ‰éœ€è¦æ¸²æŸ“çš„ä¸»å›¾ã€‚è„šæœ¬å°†æ­£å¸¸é€€å‡ºã€‚")
    bpy.ops.wm.quit_blender()

# 3. è·å–æ‰€æœ‰å·²ç»æ¸²æŸ“å¥½çš„ä¸»å›¾æ–‡ä»¶å (å·²å®Œæˆåˆ—è¡¨)
# ä½¿ç”¨é›†åˆ(set)å¯ä»¥æå¤§åœ°æé«˜æŸ¥æ‰¾æ•ˆç‡
existing_image_filenames = set(f for f in os.listdir(output_image_dir) if f.lower().endswith('.png'))

# 4. è®¡ç®—éœ€è¦æ¸²æŸ“çš„Maskæ–‡ä»¶å (æ±‚å·®é›†)
tasks_to_render_filenames = [
    mask_name for mask_name in all_mask_filenames 
    if mask_name not in existing_image_filenames
]

if not tasks_to_render_filenames:
    print("âœ… æ‰€æœ‰åœ¨Maskç›®å½•ä¸­çš„æ–‡ä»¶å‡å·²æ¸²æŸ“æˆä¸»å›¾ã€‚æ— éœ€æ“ä½œã€‚")
    bpy.ops.wm.quit_blender()

total_skipped = len(all_mask_filenames) - len(tasks_to_render_filenames)
print(f"âœ… æ£€æŸ¥å®Œæˆã€‚å…±æ‰¾åˆ° {len(all_mask_filenames)} ä¸ªMaskï¼Œå…¶ä¸­ {total_skipped} ä¸ªä¸»å›¾å·²å­˜åœ¨ã€‚")
print(f"   å°†ä¸ºå‰©ä½™çš„ {len(tasks_to_render_filenames)} ä¸ªæ–‡ä»¶æ¸²æŸ“ä¸»å›¾ã€‚")


# 5. åˆ›å»ºä¸€ä¸ªä»ç›¸æœºååˆ°ç›¸æœºå¯¹è±¡çš„å¿«é€ŸæŸ¥æ‰¾å­—å…¸
camera_map = {cam.name: cam for cam in camera_list}

# 6. è§£ææ–‡ä»¶åï¼Œä¸ºéœ€è¦æ¸²æŸ“çš„ä»»åŠ¡æ„å»ºä»»åŠ¡åˆ—è¡¨
render_tasks = []
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éå†çš„æ˜¯ç­›é€‰åçš„ tasks_to_render_filenames
for img_name in tasks_to_render_filenames:
    try:
        match = re.search(r'_(Camera_\d+_\d+)_(forward|reverse)_(\d+)\.png$', img_name)
        if not match:
            print(f"   -> âš ï¸ è­¦å‘Š: æ— æ³•è§£ææ–‡ä»¶å '{img_name}'ï¼Œæ ¼å¼ä¸åŒ¹é…ã€‚å·²è·³è¿‡ã€‚")
            continue

        cam_name, direction, frame_str = match.groups()
        frame_number = int(frame_str)
        frame_index = frame_number - 1

        cam = camera_map.get(cam_name)
        if not cam:
            print(f"   -> âš ï¸ è­¦å‘Š: åœ¨åœºæ™¯ä¸­æ‰¾ä¸åˆ°åä¸º '{cam_name}' çš„ç›¸æœº (ä»æ–‡ä»¶å '{img_name}' è§£æ)ã€‚å·²è·³è¿‡ã€‚")
            continue
        
        # è¿™é‡Œçš„move_stepéœ€è¦å’Œmaskè„šæœ¬çš„ä¿æŒä¸€è‡´
        move_step_mask = [0.045, 0.045, 0]

        if direction == 'forward':
            pos = (
                start_location[0] + move_step_mask[0] * frame_index,
                start_location[1] + move_step_mask[1] * frame_index,
                start_location[2] + move_step_mask[2] * frame_index
            )
        else: # direction == 'reverse'
            pos = (
                start_location[0] - move_step_mask[0] * frame_index,
                start_location[1] - move_step_mask[1] * frame_index,
                start_location[2] - move_step_mask[2] * frame_index
            )
        
        render_tasks.append((pos, cam, img_name))

    except Exception as e:
        print(f"   -> âŒ é”™è¯¯: è§£ææ–‡ä»¶å '{img_name}' æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}ã€‚å·²è·³è¿‡ã€‚")
        continue

if not render_tasks:
    print("âŒ è‡´å‘½é”™è¯¯: æˆåŠŸè§£æäº†0ä¸ªæ¸²æŸ“ä»»åŠ¡ã€‚è¯·æ£€æŸ¥Maskæ–‡ä»¶åæ ¼å¼æˆ–æ˜¯å¦æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆã€‚")
    bpy.ops.wm.quit_blender()

print(f"âœ… æˆåŠŸæ„å»ºäº† {len(render_tasks)} ä¸ªæ¸²æŸ“ä»»åŠ¡ã€‚")
print("="*50 + "\n")


# ==============================================================================
# ### === ä¸»å›¾æ¸²æŸ“ä¸CSVæ—¥å¿—è®°å½• (é€»è¾‘ä¿æŒä¸å˜ï¼Œä½†åŸºäºæ–°çš„render_tasks) === ###
# ==============================================================================
csv_path = os.path.join(output_path, 'render_info2.csv')
print(f"âœï¸ å°†å‘ {csv_path} å†™å…¥æ¸²æŸ“ä¿¡æ¯ (è¿½åŠ æ¨¡å¼)...")

# å‡†å¤‡å†™å…¥CSVï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™å…ˆå†™å…¥è¡¨å¤´
write_header = not os.path.exists(csv_path)

with open(csv_path, 'a', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    if write_header:
        writer.writerow([
            'image_name', 'scene_size', 'light_name', 'light_pos', 'light_strength', 'light_direction',
            'camera_pos', 'camera_direction', 'camera_focal_length', 'camera_sensor_width', 'camera_principal_point',
            'object_name', 'object_size', 'object_pos', 'object_rotation'
        ])

    for i, (pos, cam, img_name) in enumerate(render_tasks):
        print(f"ğŸ¬ æ¸²æŸ“ä¸»å›¾ ({i+1}/{len(render_tasks)}): {img_name}")
        main_obj.location = pos
        scene.camera = cam
        scene.render.filepath = os.path.join(output_image_dir, img_name)
        scene.render.image_settings.file_format = 'PNG'
        scene.render.image_settings.color_mode = 'RGB'
        bpy.ops.render.render(write_still=True)

        # --- CSVä¿¡æ¯æ”¶é›† ---
        scene_size = bounds_max - bounds_min
        scene_size_str = f"({scene_size.x:.4f},{scene_size.y:.4f},{scene_size.z:.4f})"
        
        light_infos = []
        for light_obj in [obj for obj in bpy.data.objects if obj.type == 'LIGHT']:
            light = light_obj.data
            direction_vec = light_obj.matrix_world.to_quaternion() @ Vector((0, 0, -1))
            light_infos.append({
                'name': light_obj.name,
                'pos': tuple(round(x, 4) for x in light_obj.location),
                'strength': getattr(light, 'energy', None),
                'direction': tuple(round(x, 4) for x in direction_vec) if light_obj.type in ['SPOT', 'AREA', 'SUN'] else 'N/A'
            })

        cam_pos = tuple(round(x, 4) for x in cam.location)
        cam_dir = tuple(round(x, 4) for x in cam.rotation_euler)
        principal_x = scene.render.resolution_x * (0.5 - getattr(cam.data, 'shift_x', 0.0))
        principal_y = scene.render.resolution_y * (0.5 + getattr(cam.data, 'shift_y', 0.0))
        
        obj_size = tuple(round(x, 4) for x in main_obj.dimensions)
        obj_pos = tuple(round(x, 4) for x in main_obj.location)
        obj_rot = tuple(round(math.degrees(x), 2) for x in main_obj.rotation_euler)

        # å†™å…¥æ•°æ®è¡Œ
        if not light_infos:
            writer.writerow([
                img_name, scene_size_str, 'N/A', 'N/A', 'N/A', 'N/A',
                cam_pos, cam_dir, getattr(cam.data, 'lens', None), getattr(cam.data, 'sensor_width', None),
                (round(principal_x, 2), round(principal_y, 2)), main_obj.name, obj_size, obj_pos, obj_rot
            ])
        else:
            for light_info in light_infos:
                 writer.writerow([
                    img_name, scene_size_str, light_info['name'], light_info['pos'], light_info['strength'], light_info['direction'],
                    cam_pos, cam_dir, getattr(cam.data, 'lens', None), getattr(cam.data, 'sensor_width', None),
                    (round(principal_x, 2), round(principal_y, 2)), main_obj.name, obj_size, obj_pos, obj_rot
                ])

print(f"\nâœ… ä¸»å›¾æ¸²æŸ“å®Œæˆï¼")
print(f"ğŸ“ å›¾åƒä¿å­˜åœ¨: {output_image_dir}")
print(f"ğŸ“„ æ¸²æŸ“ä¿¡æ¯ä¿å­˜åœ¨: {csv_path}")
